<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <meta name="google-site-verification" content="true">
  <meta name="msvalidate.01" content="true">
  <meta name="yandex-verification" content="true">
  <meta name="baidu-site-verification" content="true">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/pace/1.2.4/themes/black/pace-theme-minimal.min.css">
  <script src="//lf26-cdn-tos.bytecdntp.com/cdn/expire-1-M/pace/1.2.4/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.mozheyang.top","root":"/","scheme":"Muse","version":"7.7.2","exturl":false,"sidebar":{"position":"right","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"valine","storage":true,"lazyload":false,"nav":null,"activeClass":"valine"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="最近的AIGC圈子是非常热闹。 前段时间刚看到OpenAI使用自回归模型端了扩散模型在“图像生成”领域的老窝，然后立马又关注到扩散模型成为了“文本生成”领域的新贵（）。真的是神仙打架，有来有往。">
<meta property="og:type" content="article">
<meta property="og:title" content="进入大乱斗模式？自回归模型还是扩散模型？">
<meta property="og:url" content="https://www.mozheyang.top/2025/04/06/LLaDA/index.html">
<meta property="og:site_name" content="Mo&#39;s Notebook | 摸着羊的笔记本">
<meta property="og:description" content="最近的AIGC圈子是非常热闹。 前段时间刚看到OpenAI使用自回归模型端了扩散模型在“图像生成”领域的老窝，然后立马又关注到扩散模型成为了“文本生成”领域的新贵（）。真的是神仙打架，有来有往。">
<meta property="og:locale">
<meta property="og:image" content="https://www.mozheyang.top/images/LLM20250406/autor_vs_diffusion.png">
<meta property="og:image" content="https://www.mozheyang.top/images/LLM20250406/diff_normal_150ms.gif">
<meta property="og:image" content="https://www.mozheyang.top/images/LLM20250406/LLaDA_base.png">
<meta property="og:image" content="https://www.mozheyang.top/images/LLM20250406/LLaDA_methods.png">
<meta property="og:image" content="https://www.mozheyang.top/images/LLM20250406/mercury.gif">
<meta property="og:image" content="https://www.mozheyang.top/images/LLM20250406/dream-benchmark-bar.png">
<meta property="og:image" content="https://www.mozheyang.top/images/LLM20250406/dream-benchmark-table.png">
<meta property="article:published_time" content="2025-04-06T03:31:39.000Z">
<meta property="article:modified_time" content="2025-04-06T07:11:11.138Z">
<meta property="article:author" content="Geon Mo">
<meta property="article:tag" content="Information Science &amp; Technology  信息科学与技术">
<meta property="article:tag" content="Generative AI  生成式人工智能">
<meta property="article:tag" content="Large Language Model  大语言模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.mozheyang.top/images/LLM20250406/autor_vs_diffusion.png">

<link rel="canonical" href="https://www.mozheyang.top/2025/04/06/LLaDA/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true
  };
</script>

  <title>进入大乱斗模式？自回归模型还是扩散模型？ | Mo's Notebook | 摸着羊的笔记本</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Mo's Notebook | 摸着羊的笔记本" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Mo's Notebook | 摸着羊的笔记本</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">设计 / 思考 / 材料 / 信息</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-项目">

    <a href="/projects/" rel="section"><i class="fa fa-fw fa-coffee"></i>项目</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="search-pop-overlay">
  <div class="popup search-popup">
      <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <span class="popup-btn-summary">
    <i class="fa fa-edit"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>
<div id="summary-result">
  <div id="no-summary">
    <i class="fa fa-commenting fa-5x fa-fw"></i>
  </div>
</div>

  </div>
</div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://www.mozheyang.top/2025/04/06/LLaDA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Geon Mo">
      <meta itemprop="description" content="主业搬砖，兼职磕盐">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mo's Notebook | 摸着羊的笔记本">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          进入大乱斗模式？自回归模型还是扩散模型？
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-04-06 11:31:39 / 修改时间：15:11:11" itemprop="dateCreated datePublished" datetime="2025-04-06T11:31:39+08:00">2025-04-06</time>
            </span>

          
            <span id="/2025/04/06/LLaDA/" class="post-meta-item leancloud_visitors" data-flag-title="进入大乱斗模式？自回归模型还是扩散模型？" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2025/04/06/LLaDA/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2025/04/06/LLaDA/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>2.1k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>最近的AIGC圈子是非常热闹。</p>
<p>前段时间刚看到<a target="_blank" rel="noopener" href="https://openai.com/index/introducing-4o-image-generation/">OpenAI使用自回归模型</a>端了扩散模型在“图像生成”领域的老窝，然后立马又关注到扩散模型成为了“文本生成”领域的新贵（）。真的是神仙打架，有来有往。</p>
<p><img src="/images/LLM20250406/autor_vs_diffusion.png" alt="vs"></p>
<span id="more"></span>
<p>最近的一篇论文《LLaDA: Learning Latent Diffusion Models for Autoregressive Text Generation》，作者认为扩散模型可以成为自回归模型之外的可行选择。<br>本文主要分为三个部分：</p>
<ol>
<li>核心论点：扩散模型可以成为自回归模型之外的可行选择</li>
<li>论据支持：LLaDA 的全面实验验证</li>
<li>方法创新：掩码扩散框架的设计</li>
</ol>
<h1 id="核心论点：扩散模型可以成为自回归模型之外的可行选择"><a href="#核心论点：扩散模型可以成为自回归模型之外的可行选择" class="headerlink" title="核心论点：扩散模型可以成为自回归模型之外的可行选择"></a>核心论点：扩散模型可以成为自回归模型之外的可行选择</h1><p><strong>主要挑战</strong>：<br>当前大语言模型（LLMs）普遍采用自回归模型（Autoregressive Models, ARMs），通过逐词预测实现文本生成。但作者认为，<strong>自回归结构并非LLMs能力的唯一根源</strong>，其本质源于生成建模原则（如最大似然估计），而扩散模型（Diffusion Models）同样能实现类似甚至更优的表现。</p>
<p><strong>核心主张</strong>：  </p>
<ol>
<li><strong>生成建模原则是关键</strong>：LLMs的核心能力（如上下文学习、指令跟随）源于对数据分布的建模，而非自回归结构本身。  </li>
<li><strong>自回归模型的局限性</strong>：逐词生成导致计算效率低、难以处理逆向推理任务（如“逆向诅咒”）。  </li>
<li><strong>扩散模型的潜力</strong>：通过掩码扩散建模双向依赖关系，可实现更灵活、鲁棒的生成。</li>
</ol>
<p><img src="/images/LLM20250406/diff_normal_150ms.gif" alt=""></p>
<hr>
<h1 id="论据支持：LLaDA-的全面实验验证"><a href="#论据支持：LLaDA-的全面实验验证" class="headerlink" title="论据支持：LLaDA 的全面实验验证"></a>论据支持：LLaDA 的全面实验验证</h1><p><strong>1. 性能对标主流LLMs</strong><br>• <strong>基准测试</strong>：在MMLU、GSM8K、代码生成（HumanEval）等15项任务中，8B参数的LLaDA与LLaMA3 8B表现相当，部分任务（如中文理解CMMLU）显著优于LLaMA2 7B。<br>• <strong>逆向任务突破</strong>：在“逆向诗歌补全”任务中，LLaDA以42.4%准确率超过GPT-4o（34.3%），证明其双向建模优势。<br><img src="/images/LLM20250406/LLaDA_base.png" alt=""></p>
<p><strong>2. 可扩展性验证</strong><br>• 从1B到8B参数，LLaDA的训练损失随计算量（FLOPs）稳定下降，与自回归模型基线趋势一致，验证扩散模型在大规模训练中的可行性。</p>
<p><strong>3. 指令跟随与多轮对话</strong><br>• 经过监督微调（SFT），LLaDA展现出流畅的多语言对话能力（如中英德翻译），生成文本连贯且符合上下文逻辑。</p>
<hr>
<h1 id="方法创新：掩码扩散框架的设计"><a href="#方法创新：掩码扩散框架的设计" class="headerlink" title="方法创新：掩码扩散框架的设计"></a>方法创新：掩码扩散框架的设计</h1><p><strong>1. 前向与反向过程</strong><br>• <strong>前向掩码</strong>：随机按时间步长 ( t \in [0,1] ) 对输入序列逐步掩码（如t=0为完整文本，t=1全掩码）。<br>• <strong>反向生成</strong>：训练Transformer预测被掩码的token，通过多步迭代重建完整文本（类似图像扩散的去噪过程）。<br><img src="/images/LLM20250406/LLaDA_methods.png" alt=""></p>
<p><strong>2. 训练目标</strong><br>• 优化对数似然上界（式3），仅对掩码位置计算交叉熵损失：  </p>
<script type="math/tex; mode=display">
  \mathcal{L}(\theta) = -\mathbb{E}_{t,x_0,x_t} \left[ \frac{1}{t} \sum_{i=1}^L \mathbf{1}[x_t^i=M] \log p_\theta(x_0^i|x_t) \right]</script><p><strong>3. 推理优化策略</strong><br>• <strong>动态长度训练</strong>：1%的训练数据采用随机长度（1-4096 token），提升模型对可变长度输入的适应性。<br>• <strong>半自回归生成</strong>：将输出分块生成，块内并行预测掩码，兼顾效率与质量。<br>• <strong>低置信度重掩码</strong>：在反向过程中优先重掩码低置信度预测，加速收敛。</p>
<hr>
<h1 id="核心贡献与意义"><a href="#核心贡献与意义" class="headerlink" title="核心贡献与意义"></a>核心贡献与意义</h1><p><strong>1. 理论突破</strong><br>• <strong>首次验证扩散模型的LLM潜力</strong>：以80亿参数规模证明扩散模型在语言任务中可媲美主流自回归模型。<br>• <strong>统一视角</strong>：揭示掩码扩散与任意顺序自回归模型（AO-ARM）的等价性（式15），为双向建模提供理论支撑。</p>
<p><strong>2. 工程实践</strong><br>• <strong>高效训练框架</strong>：提出动态掩码策略、Warmup-Stable-Decay学习率调度等方法，实现2.3万亿token的高效预训练（0.13万H800 GPU小时）。<br>• <strong>开源生态</strong>：发布代码与模型权重（<a target="_blank" rel="noopener" href="https://ml-gsai.github.io/LLaDA-demo/">https://ml-gsai.github.io/LLaDA-demo/</a>），推动非自回归LLM研究。</p>
<p><strong>3. 应用前景</strong><br>• <strong>解决逆向诅咒</strong>：在需要双向推理的任务（如诗歌补全、逻辑回溯）中表现突出。<br>• <strong>更灵活生成</strong>：支持多步采样调控生成质量，为可控文本生成提供新思路。</p>
<hr>
<h1 id="局限与未来方向"><a href="#局限与未来方向" class="headerlink" title="局限与未来方向"></a>局限与未来方向</h1><p>• <strong>计算成本</strong>：扩散模型推理需多步迭代，实时性弱于自回归模型。<br>• <strong>扩展潜力</strong>：尚未探索强化学习对齐、多模态融合等后续优化。<br>• <strong>架构优化</strong>：可设计更适合扩散模型的注意力机制与位置编码。</p>
<h1 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h1><ul>
<li><p><strong>商业化应用：</strong>2025年2月26日，Inception Labs发布了Mercury Coder，宣称是首个商业化规模的dLLM。其核心创新在于​​并行生成机制​​，显著提升效率，在NVIDIA H100上生成速度达1000 tokens/秒，比传统自回归模型快5-20倍，且运行成本降低5-10倍。Inception Labs由斯坦福教授Stefano Ermon等创立，其团队包括MDLM论文作者Volodymyr Kuleshov，显示出研究与商业化的紧密联系。<br><img src="/images/LLM20250406/mercury.gif" alt=""></p>
</li>
<li><p><strong>近期SOTA：</strong>香港大学与华为诺亚方舟实验室推出的​<a target="_blank" rel="noopener" href="https://hkunlp.github.io/blog/2025/dream/">​Dream 7B</a>​​（扩散推理模型），通过​​扩散架构创新+AR知识迁移​​，证明了扩散模型在大规模语言任务中的竞争力。其​​规划能力优势​​和​​推理灵活性​​为智能体、代码生成等场景提供新可能。</p>
</li>
</ul>
<p><img src="/images/LLM20250406/dream-benchmark-bar.png" alt="一般任务、数学任务、编码任务和规划任务的语言模型比较"></p>
<p class="refs">一般任务、数学任务、编码任务和规划任务的语言模型比较</p>

<p><img src="/images/LLM20250406/dream-benchmark-table.png" alt="语言模型在标准评估基准上的比较"></p>
<p class="refs">语言模型在标准评估基准上的比较</p>
    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Geon Mo
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://www.mozheyang.top/2025/04/06/LLaDA/" title="进入大乱斗模式？自回归模型还是扩散模型？">https://www.mozheyang.top/2025/04/06/LLaDA/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-cn" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
  <li class="post-copyright-contact">
    <strong>联系方式： </strong>
    <a href="mailto:mozheyang@outlook.com" target="_blank">mozheyang@outlook.com</a>
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/Information-Science-Technology-%E4%BF%A1%E6%81%AF%E7%A7%91%E5%AD%A6%E4%B8%8E%E6%8A%80%E6%9C%AF/" rel="tag"><i class="fa fa-tag"></i> Information Science & Technology  信息科学与技术</a>
              <a href="/tags/Generative-AI-%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" rel="tag"><i class="fa fa-tag"></i> Generative AI  生成式人工智能</a>
              <a href="/tags/Large-Language-Model-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" rel="tag"><i class="fa fa-tag"></i> Large Language Model  大语言模型</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/10/13/nobel2024/" rel="prev" title="科学不存在了吗？2024年诺贝尔奖与AI4Science">
      <i class="fa fa-chevron-left"></i> 科学不存在了吗？2024年诺贝尔奖与AI4Science
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/04/06/qingming2025/" rel="next" title="记忆中的爷爷和奶奶">
      记忆中的爷爷和奶奶 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E8%AE%BA%E7%82%B9%EF%BC%9A%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E6%88%90%E4%B8%BA%E8%87%AA%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%B9%8B%E5%A4%96%E7%9A%84%E5%8F%AF%E8%A1%8C%E9%80%89%E6%8B%A9"><span class="nav-number">1.</span> <span class="nav-text">核心论点：扩散模型可以成为自回归模型之外的可行选择</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%BA%E6%8D%AE%E6%94%AF%E6%8C%81%EF%BC%9ALLaDA-%E7%9A%84%E5%85%A8%E9%9D%A2%E5%AE%9E%E9%AA%8C%E9%AA%8C%E8%AF%81"><span class="nav-number">2.</span> <span class="nav-text">论据支持：LLaDA 的全面实验验证</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%B9%E6%B3%95%E5%88%9B%E6%96%B0%EF%BC%9A%E6%8E%A9%E7%A0%81%E6%89%A9%E6%95%A3%E6%A1%86%E6%9E%B6%E7%9A%84%E8%AE%BE%E8%AE%A1"><span class="nav-number">3.</span> <span class="nav-text">方法创新：掩码扩散框架的设计</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E8%B4%A1%E7%8C%AE%E4%B8%8E%E6%84%8F%E4%B9%89"><span class="nav-number">4.</span> <span class="nav-text">核心贡献与意义</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B1%80%E9%99%90%E4%B8%8E%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="nav-number">5.</span> <span class="nav-text">局限与未来方向</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%90%8E%E7%BB%AD"><span class="nav-number">6.</span> <span class="nav-text">后续</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Geon Mo"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Geon Mo</p>
  <div class="site-description" itemprop="description">主业搬砖，兼职磕盐</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">85</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:mozheyang@outlook.com" title="E-Mail → mailto:mozheyang@outlook.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="/atom.xml" title="RSS → &#x2F;atom.xml"><i class="fa fa-fw fa-rss"></i>RSS</a>
      </span>
      <span class="links-of-author-item">
        <a href="/sitemap.xml" title="Sitemap → &#x2F;sitemap.xml"><i class="fa fa-fw fa-sitemap"></i>Sitemap</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      我的朋友
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://slykiten.com/" title="https:&#x2F;&#x2F;slykiten.com&#x2F;" rel="noopener" target="_blank">狡猫三窝</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://fatesinger.com/" title="https:&#x2F;&#x2F;fatesinger.com&#x2F;" rel="noopener" target="_blank">Fatesinger-大发</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://dragonscience.top/" title="https:&#x2F;&#x2F;dragonscience.top&#x2F;" rel="noopener" target="_blank">Dragon🐉Science</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="beian">
      <img src="https://www.mozheyang.top/images/beian.png" style="display: inline-block; margin-right: 5px; margin-bottom: -5px">  <a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">桂ICP备17010030号</a>
  </div>

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Geon Mo</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">185k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">5:37</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_userview">
      <span class="post-meta-item-icon">
        <i class="fa fa-fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pageview">
      <span class="post-meta-item-icon">
        <i class="fa fa-fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//lf9-cdn-tos.bytecdntp.com/cdn/expire-1-M/medium-zoom/1.0.6/medium-zoom.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/mathjax/3.2.0/es5/tex-mml-chtml.min.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//lf26-cdn-tos.bytecdntp.com/cdn/expire-1-M/valine/1.4.16/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'XXDgldaYnClF172bvGQcHJj3-9Nh9j0Va',
      appKey     : 'WTlVtXkhnVRf7Gkjryijsy2Q',
      placeholder: "请开始你的表演",
      avatar     : 'mp',
      avatar_cdn : 'https://cravatar.cn/avatar/', 
      meta       : guest,
      pageSize   : '5' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : 'https://xxdglday.lc-cn-n1-shared.com'
    });
  }, window.Valine);
});
</script>

  
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/axios@1.1.2/dist/axios.min.js"></script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
